{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4259c799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'EnglandWalesmeasles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(data_dir)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mEnglandWalesmeasles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data \u001b[38;5;28;01mas\u001b[39;00m engwal\n\u001b[1;32m     15\u001b[0m distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglandWalesdistances.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlaser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'EnglandWalesmeasles'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from laser.core.propertyset import PropertySet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "data_dir = os.path.join('..', \"data\")\n",
    "sys.path.append(data_dir)\n",
    "\n",
    "from EnglandWalesmeasles import data as engwal\n",
    "distances = np.load(os.path.join(\"..\", \"data\", \"EnglandWalesdistances.npy\"))\n",
    "\n",
    "import laser.core\n",
    "import laser.generic\n",
    "\n",
    "print(f\"{np.__version__=}\")\n",
    "print(f\"{laser.core.__version__=}\")\n",
    "print(f\"{laser.generic.__version__=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWdata = pd.DataFrame([{\"name\": placename,\n",
    "         \"population\": place.population[0],\n",
    "         \"latitude\": place.latitude,\n",
    "         \"longitude\": place.longitude} for placename, place in engwal.places.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWdata[EWdata[\"name\"].str.contains(\"London\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWdata[\"cases\"] = EWdata[\"name\"].apply(lambda name: engwal.places[name].cases)\n",
    "EWdata['births' ] = EWdata[\"name\"].apply(lambda name: engwal.places[name].births)\n",
    "EWdata[\"prop_zero\"] = EWdata[\"cases\"].apply(lambda x: np.mean(np.array(x) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EWdata.loc[507]['births']/EWdata.loc[507]['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022f760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(EWdata['population']), EWdata['prop_zero'], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "output_dir = os.path.join('..', 'outputs3')\n",
    "params = pd.read_csv(os.path.join(output_dir, \"params.csv\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "for fname in range(100):\n",
    "   \n",
    "    with open(os.path.join(output_dir, 'EWoutputs_gravity_'+str(fname)+'.pkl'), \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "    # x.cases_test: shape (days, 954)\n",
    "    cases_test = np.array(x.cases_test)\n",
    "    incidence = np.array(x.incidence)\n",
    "    populations = np.array(x.populations[0 ,:])\n",
    "    # Aggregate daily to weekly: sum every 7 days along axis 0\n",
    "    num_weeks = cases_test.shape[0] // 7\n",
    "    weekly_cases = cases_test[:num_weeks*7].reshape(num_weeks, 7, 954).sum(axis=1)\n",
    "    weekly_incidence = incidence[:num_weeks*7].reshape(num_weeks, 7, 954).sum(axis=1)\n",
    "    # Create a DataFrame for this parameter set, matching EWdata's structure\n",
    "    df = pd.DataFrame({\n",
    "        \"name\": EWdata[\"name\"],\n",
    "        \"population\": populations,\n",
    "        \"cases\": list(weekly_cases.T),  # each entry is a list of weekly cases for that place\n",
    "        \"incidence\": list(weekly_incidence.T)  # each entry is a list of weekly cases for that place\n",
    "    })\n",
    "    df[\"k\"] = params.iloc[fname][\"k\"]\n",
    "    df[\"b\"] = params.iloc[fname][\"b\"]\n",
    "    df[\"c\"] = params.iloc[fname][\"c\"]\n",
    "    #df.set_index([\"k\", \"a\", \"c\", \"name\"], inplace=True)\n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_result in results:\n",
    "    df_result[\"prop_zero\"] = df_result[\"incidence\"].apply(lambda x: np.mean(np.array(x[1040:]) ==0 ))\n",
    "    df_result[\"prop_low\"] = df_result[\"incidence\"].apply(lambda x: np.mean(np.array(x[1040:]) <=2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 1. Define fitting functions for mean and variance\n",
    "def logistic(x, x0, k):\n",
    "    # Logistic function bounded between 0 and 1, transitions from 1 to 0 as x increases\n",
    "    return 1 / (1 + np.exp(k * (x - x0)))\n",
    "\n",
    "def fit_mean_var(x, y):\n",
    "    # Fit a logistic to the mean\n",
    "    # Initial guess: midpoint at median(x), width=1\n",
    "    p0 = [np.median(x), 1.0]\n",
    "    bounds = ([-np.inf, 0.01], [np.inf, 10.0])\n",
    "    popt_mean, _ = curve_fit(logistic, x, y, p0=p0, bounds=bounds, maxfev=10000)\n",
    "    return popt_mean\n",
    "\n",
    "# 3. Define similarity metric (sum of squared differences of mean and variance fits)\n",
    "def similarity_metric(mean_data, mean_sim):\n",
    "    # Evaluate both curves on a common grid\n",
    "    x_grid = np.linspace(2.5, 6.5, 200)\n",
    "    data_curve = logistic(x_grid, *mean_data)\n",
    "    sim_curve = logistic(x_grid, *mean_sim)\n",
    "    # Similarity: sum of squared differences between the curves\n",
    "    mean_diff = np.sum((sim_curve - data_curve) ** 2)\n",
    "    return mean_diff\n",
    "\n",
    "params = []\n",
    "sim_metrics = []\n",
    "\n",
    "for i, df_result in enumerate(results):\n",
    "    # Plot observed and simulated data\n",
    "    logpop_obs = np.log10(EWdata['population'])\n",
    "    prop_zero_obs = EWdata['prop_zero']\n",
    "    logpop_sim = np.log10(df_result['population'])\n",
    "    prop_zero_sim = df_result['prop_zero']\n",
    "\n",
    "    # Fit to observed\n",
    "    popt_obs = fit_mean_var(logpop_obs, prop_zero_obs)\n",
    "    popt_sim = fit_mean_var(logpop_sim, prop_zero_sim)\n",
    "    # Similarity metric\n",
    "    sim = similarity_metric(popt_obs, popt_sim)\n",
    "    k = df_result['k'].iloc[0]\n",
    "    a = df_result['b'].iloc[0]\n",
    "    c = df_result['c'].iloc[0]\n",
    "    params.append((k, a, c))\n",
    "    sim_metrics.append(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with k, b, c, and similarity score, then sort by similarity\n",
    "params_df = pd.DataFrame(params, columns=['k', 'b', 'c'])\n",
    "params_df['similarity'] = sim_metrics\n",
    "ranked_params = params_df.sort_values('similarity').reset_index(drop=True)\n",
    "ranked_params[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ced302",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(6, 2, figsize=(14, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(12):\n",
    "    # Get the parameter set with the idx-th lowest similarity\n",
    "    k_best, b_best, c_best = ranked_params.loc[idx, ['k', 'b', 'c']]\n",
    "    sim_score = ranked_params.loc[idx, 'similarity']\n",
    "    # Find the corresponding result DataFrame\n",
    "    for df in results:\n",
    "        if np.isclose(df['k'].iloc[0], k_best) and np.isclose(df['b'].iloc[0], b_best) and np.isclose(df['c'].iloc[0], c_best):\n",
    "            df_best = df\n",
    "            break\n",
    "\n",
    "    logpop_sim = np.log10(df_best['population'])\n",
    "    prop_zero_sim = df_best['prop_zero']\n",
    "\n",
    "    # Fit logistic to simulation\n",
    "    popt_sim = fit_mean_var(logpop_sim, prop_zero_sim)\n",
    "    # Fit logistic to observed (reuse from above)\n",
    "    popt_obs = fit_mean_var(np.log10(EWdata['population']), EWdata['prop_zero'])\n",
    "\n",
    "    xfit = np.linspace(2.8, 6.4, 200)\n",
    "    axes[idx].plot(np.log10(EWdata['population']), EWdata['prop_zero'], 'o', label='Observed', alpha=0.6)\n",
    "    axes[idx].plot(logpop_sim, prop_zero_sim, 'o', label='Simulated', alpha=0.6)\n",
    "    axes[idx].plot(xfit, logistic(xfit, *popt_obs), '-', label='Obs fit', color='C0')\n",
    "    axes[idx].plot(xfit, logistic(xfit, *popt_sim), '-', label='Sim fit', color='C1')\n",
    "    axes[idx].set_title(f\"k={k_best:.1e}, b={b_best:.2f}, c={c_best:.2f}, similarity={sim_score:.3f}\")\n",
    "    axes[idx].set_xlabel(\"log10(Population)\")\n",
    "    axes[idx].set_ylabel(\"Proportion zero\")\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae269c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 best simulations (lowest similarity)\n",
    "top10 = ranked_params.iloc[:10]\n",
    "\n",
    "# Collect the corresponding result DataFrames\n",
    "df_top10 = []\n",
    "for idx, row in top10.iterrows():\n",
    "    k_best, b_best, c_best = row[['k', 'b', 'c']]\n",
    "    for df in results:\n",
    "        if np.isclose(df['k'].iloc[0], k_best) and np.isclose(df['b'].iloc[0], b_best) and np.isclose(df['c'].iloc[0], c_best):\n",
    "            df_top10.append(df)\n",
    "            break\n",
    "\n",
    "# Stack prop_zero and population for averaging\n",
    "populations = np.stack([np.log10(df['population'].values) for df in df_top10])\n",
    "prop_zeros = np.stack([df['prop_zero'].values for df in df_top10])\n",
    "\n",
    "# Compute mean and std across the top 10\n",
    "logpop_sim_mean = populations.mean(axis=0)\n",
    "prop_zero_sim_mean = prop_zeros.mean(axis=0)\n",
    "prop_zero_sim_std = prop_zeros.std(axis=0)\n",
    "\n",
    "logpop_obs = np.log10(EWdata['population'])\n",
    "prop_zero_obs = EWdata['prop_zero']\n",
    "#logpop_sim = np.log10(df_best['population'])\n",
    "#prop_zero_sim = df_best['prop_zero']\n",
    "\n",
    "plt.figure(figsize=(9, 6), dpi=200)\n",
    "# Use colorblind-friendly colors (e.g., from Color Universal Design palette)\n",
    "# Blue: #0072B2, Orange: #E69F00\n",
    "plt.scatter(logpop_obs, prop_zero_obs, s=40, color='#0072B2', label='Observed', alpha=0.8, edgecolor='k', linewidth=0.7)\n",
    "plt.scatter(logpop_sim_mean, prop_zero_sim_mean, s=40, color='#E69F00', label='Simulated', alpha=0.8, marker='s', edgecolor='k', linewidth=0.7)\n",
    "\n",
    "plt.xlabel(\"City population\", fontsize=18)\n",
    "plt.ylabel(\"Proportion of weeks \\n with no reported cases\", fontsize=18)\n",
    "plt.title(\"England + Wales 954 city dataset \\n Measles fadeout and reinvasion dynamics, 1944-1964\", fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "# Set custom x-ticks and labels for log10 scale\n",
    "xticks = [3, 4, 5, 6]\n",
    "xticklabels = [r\"$10^{%g}$\" % x for x in xticks]\n",
    "plt.xticks(xticks, xticklabels, fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Plot spatial distribution of cities with marker size proportional to log(population)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "# Scatter plot: marker size proportional to log(population)\n",
    "sizes =   0.5*np.sqrt(EWdata['population'])  # adjust scaling as needed\n",
    "sc = ax.scatter(EWdata['longitude'], EWdata['latitude'], s=sizes, alpha=0.8, c='C0', edgecolor='k', linewidth=1.0)\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Cities in England & Wales\\nMarker size ~ log10(population)')\n",
    "\n",
    "# # Optional: Add England & Wales borders using geopandas if available\n",
    "# try:\n",
    "#     # Plot England & Wales borders from local shapefile\n",
    "#     shapefile_path = os.path.join('..', 'ne_110m_admin_0_map_units', 'ne_110m_admin_0_map_units.shp')\n",
    "#     borders = gpd.read_file(shapefile_path)\n",
    "#     # Filter for United Kingdom, then further for England and Wales if possible\n",
    "#     uk = borders[borders['SOVEREIGNT'] == 'United Kingdom']\n",
    "#     # If there are subregions, filter for England and Wales\n",
    "#     if 'NAME' in uk.columns:\n",
    "#         england_wales = uk[uk['NAME'].isin(['England', 'Wales'])]\n",
    "#         if not england_wales.empty:\n",
    "#             england_wales.boundary.plot(ax=ax, color='k', linewidth=1)\n",
    "#         else:\n",
    "#             uk.boundary.plot(ax=ax, color='k', linewidth=1)\n",
    "#     else:\n",
    "#         uk.boundary.plot(ax=ax, color='k', linewidth=1)\n",
    "# except ImportError:\n",
    "#     print(\"geopandas not installed, skipping borders.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not plot borders: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavelet phase analysis\n",
    "import pywt\n",
    "\n",
    "def pad_data(x):\n",
    "    \"\"\"\n",
    "    Pad data to the next power of 2\n",
    "    \"\"\"\n",
    "    nx = len(x) # number of samples\n",
    "    nx2 = (2**np.ceil(np.log(nx)/np.log(2))).astype(int) # next power of 2\n",
    "    x2 = np.zeros(nx2, dtype=x.dtype) # pad to next power of 2\n",
    "    offset = (nx2-nx)//2 # offset\n",
    "    x2[offset:(offset+nx)] = x # copy\n",
    "    return x2\n",
    "\n",
    "def log_transform(x, debug=1):\n",
    "    \"\"\"\n",
    "    Log transform for case data\n",
    "    \"\"\" \n",
    "    # add one and take log\n",
    "    x = np.log(x+1)\n",
    "    # set mean=0 and std=1\n",
    "    m = np.mean(x)\n",
    "    s = np.std(x)\n",
    "    x = (x - m)/s\n",
    "    return x\n",
    "\n",
    "\n",
    "def calc_Ws(cases):\n",
    "    # transform case data\n",
    "    log_cases = pad_data(log_transform(cases))\n",
    "\n",
    "    # setup and execute wavelet transform\n",
    "    # https://pywavelets.readthedocs.io/en/latest/ref/cwt.html#morlet-wavelet\n",
    "    wavelet = pywt.ContinuousWavelet('cmor2-1')\n",
    "\n",
    "    dt = 1 # 2 weeks\n",
    "    widths = np.logspace(np.log10(1), np.log10(7*52), int(7*52))\n",
    "    [cwt, frequencies] = pywt.cwt(log_cases, widths, wavelet, dt)\n",
    "\n",
    "    # Number of time steps in padded time series\n",
    "    nt = len(cases)\n",
    "    # trim matrix\n",
    "    offset = (cwt.shape[1] - nt) // 2\n",
    "    cwt = cwt[:, offset:offset + nt]\n",
    "\n",
    "    return cwt, frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cases for London from EWdata\n",
    "london_idx = EWdata[EWdata[\"name\"].str.contains(\"London\", case=False)].index[0]\n",
    "london_cases = EWdata[EWdata[\"name\"].str.contains(\"London\", case=False)][\"cases\"].iloc[0]\n",
    "ref_cwt, frequencies = calc_Ws(np.array(london_cases.flatten()))\n",
    "distances_from_london = distances[london_idx, :]\n",
    "\n",
    "x = np.zeros(len(EWdata))\n",
    "y = np.zeros(len(EWdata))\n",
    "y2 = np.zeros(len(EWdata))\n",
    "for i, row in EWdata.iterrows():\n",
    "    if distances_from_london[i] > 30:\n",
    "        continue\n",
    "    cwt, frequencies = calc_Ws(row[\"cases\"].flatten())\n",
    "    diff = ref_cwt*np.conj(cwt)\n",
    "    ind = np.where(np.logical_and(frequencies < 1/(1.5 * 52), frequencies > 1 / (3 * 52)))\n",
    "    diff1 = diff[ind[0], :]\n",
    "    x[i] = distances_from_london[i]\n",
    "    y[i] = np.angle(np.mean(diff1))\n",
    "    ind2 = np.where(np.logical_and(frequencies < 1/(0.75 * 52), frequencies > 1 / (1.25 * 52)))\n",
    "    diff2 = diff[ind2[0], :]\n",
    "    y2[i] = np.angle(np.mean(diff2))\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.xlabel(\"Distance from London\")\n",
    "plt.ylabel(\"Phase difference\")\n",
    "plt.title(\"Phase difference of London wavelet transform\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c875924",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, -y*180/np.pi, 'o')\n",
    "plt.xlim(5, 30)\n",
    "plt.ylim(-90, 0)\n",
    "plt.xlabel(\"Distance from London\")\n",
    "plt.ylabel(\"Phase difference\")\n",
    "plt.title(\"Phase difference of London wavelet transform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bcc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cases for London from EWdata\n",
    "# For each simulation in results, compute phase difference arrays y_sim and y2_sim\n",
    "phase_diff_results = []\n",
    "\n",
    "london_idx = EWdata[EWdata[\"name\"].str.contains(\"London\", case=False)].index[0]\n",
    "distances_from_london = distances[london_idx, :]\n",
    "\n",
    "for sim_idx, df_sim in enumerate(results):\n",
    "    # Get London cases for this simulation\n",
    "    london_cases_sim = df_sim[df_sim[\"name\"].str.contains(\"London\", case=False)][\"cases\"].iloc[0]\n",
    "    ref_cwt_sim, frequencies_sim = calc_Ws(np.array(london_cases_sim[520:]).flatten())\n",
    "    x_sim = np.zeros(len(df_sim))\n",
    "    y_sim = np.zeros(len(df_sim))\n",
    "    y2_sim = np.zeros(len(df_sim))\n",
    "    for i, row in df_sim.iterrows():\n",
    "        if distances_from_london[i] > 30:\n",
    "            continue\n",
    "        cwt_sim, frequencies_sim = calc_Ws(np.array(row[\"cases\"][520:]).flatten())\n",
    "        diff_sim = ref_cwt_sim * np.conj(cwt_sim)\n",
    "        ind = np.where(np.logical_and(frequencies_sim < 1/(1.5 * 52), frequencies_sim > 1 / (3 * 52)))\n",
    "        diff1_sim = diff_sim[ind[0], :]\n",
    "        x_sim[i] = distances_from_london[i]\n",
    "        y_sim[i] = np.angle(np.mean(diff1_sim))\n",
    "        ind2 = np.where(np.logical_and(frequencies_sim < 1/(0.75 * 52), frequencies_sim > 1 / (1.25 * 52)))\n",
    "        diff2_sim = diff_sim[ind2[0], :]\n",
    "        y2_sim[i] = np.angle(np.mean(diff2_sim))\n",
    "    phase_diff_results.append({\n",
    "        \"sim_idx\": sim_idx,\n",
    "        \"x\": x_sim,\n",
    "        \"y\": y_sim,\n",
    "        \"y2\": y2_sim\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"phase_diff_results2.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(phase_diff_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d101fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"phase_diff_results2.pkl\"), \"rb\") as f:\n",
    "    phase_diff_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbe08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7285c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(100):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left plot: Phase difference\n",
    "    axs[0].plot(x, -y*180/np.pi, 'o', label='Observed')\n",
    "    axs[0].plot(phase_diff_results[14][\"x\"], -phase_diff_results[ind][\"y\"]*180/np.pi, 'o', label='Simulated')\n",
    "    axs[0].set_xlim(5, 30)\n",
    "    axs[0].set_ylim(-90, 90)\n",
    "    axs[0].set_xlabel(\"Distance from London\")\n",
    "    axs[0].set_ylabel(\"Phase difference\")\n",
    "    axs[0].set_title(\"Phase difference of London wavelet transform\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Right plot: Proportion zero vs log10(population)\n",
    "    axs[1].plot(np.log10(EWdata['population']), EWdata['prop_zero'], 'o', label='Observed', alpha=0.6)\n",
    "    axs[1].plot(np.log10(results[10]['population']), results[ind][\"prop_low\"], '.', label='Simulated')\n",
    "    axs[1].set_xlabel(\"log10(Population)\")\n",
    "    axs[1].set_ylabel(\"Proportion zero\")\n",
    "    axs[1].set_title(\"Proportion zero vs log10(Population)\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# 1. Compute similarity between observed and each simulation's phase difference curve\n",
    "# We'll use the y (phase difference) vs x (distance) arrays\n",
    "\n",
    "# Only consider cities within 5-30 km (as in previous plots)\n",
    "mask = (x >= 5) & (x <= 30)\n",
    "x_obs = x[mask]\n",
    "y_obs = y[mask]\n",
    "\n",
    "sim_scores = []\n",
    "for sim in phase_diff_results:\n",
    "    x_sim = sim[\"x\"]\n",
    "    y_sim = sim[\"y\"]\n",
    "    # Interpolate simulation phase difference to observed x values for fair comparison\n",
    "    mask_sim = (x_sim >= 5) & (x_sim <= 30)\n",
    "    if np.sum(mask_sim) < 5:  # skip if not enough points\n",
    "        sim_scores.append(np.inf)\n",
    "        continue\n",
    "    # Interpolate simulation y to observed x points\n",
    "    try:\n",
    "        y_sim_interp = np.interp(x_obs, x_sim[mask_sim], y_sim[mask_sim])\n",
    "        score = np.sum((y_obs - y_sim_interp) ** 2)\n",
    "    except Exception:\n",
    "        score = np.inf\n",
    "    sim_scores.append(score)\n",
    "\n",
    "# 2. Get indices of the 10 best simulations (lowest scores)\n",
    "top10_idx = np.argsort(sim_scores)[:10]\n",
    "\n",
    "# 3. Plot\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.plot(x_obs, -y_obs*180/np.pi, 'o', color='#0072B2', label='Observed', linewidth=2, markersize=6)\n",
    "\n",
    "# Color palette for simulations\n",
    "import matplotlib.cm as cm\n",
    "colors = cm.viridis(np.linspace(0, 1, 10))\n",
    "# Average the top 10 simulations' phase difference curves (interpolated to observed x points)\n",
    "y_sims_interp = []\n",
    "for idx in top10_idx:\n",
    "    sim = phase_diff_results[idx]\n",
    "    x_sim = sim[\"x\"]\n",
    "    y_sim = sim[\"y\"]\n",
    "    mask_sim = (x_sim >= 5) & (x_sim <= 30)\n",
    "    if np.sum(mask_sim) < 5:\n",
    "        continue\n",
    "    y_interp = np.interp(x_obs, x_sim[mask_sim], y_sim[mask_sim])\n",
    "    y_sims_interp.append(y_interp)\n",
    "y_sims_interp = np.array(y_sims_interp)\n",
    "y_sim_mean = np.mean(y_sims_interp, axis=0)\n",
    "y_sim_std = np.std(y_sims_interp, axis=0)\n",
    "\n",
    "#plt.plot(x_obs, -y_sim_mean*180/np.pi, 'o', color='#E69F00', linewidth=2.5, label='Simulated (mean)')\n",
    "plt.errorbar(x_obs, -y_sim_mean*180/np.pi, yerr=y_sim_std*180/np.pi, marker='s', fmt='none', ecolor='#E69F00', capsize=3, label='Simulated (Â±1 std)')\n",
    "\n",
    "plt.xlim(5, 30)\n",
    "plt.ylim(-90, 20)\n",
    "plt.xlabel(\"Distance from London (km)\", fontsize=14)\n",
    "plt.ylabel(\"Phase difference (degrees)\", fontsize=14)\n",
    "plt.title(\"Top 10 Simulations: Phase difference vs. Distance\", fontsize=16)\n",
    "plt.legend(fontsize=10, loc='lower left', ncol=2, frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b103f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total cases across all towns for each simulation in results\n",
    "total_cases_per_sim = []\n",
    "\n",
    "for df in results:\n",
    "    # Each row's \"cases\" is a list/array of weekly cases for that town\n",
    "    # Stack all towns' cases into a 2D array: shape (num_towns, num_weeks)\n",
    "    cases_matrix = np.stack(df[\"incidence\"].values)\n",
    "    # Sum across towns (axis=0) to get total cases per week\n",
    "    total_cases = cases_matrix.sum(axis=0)\n",
    "    total_cases_per_sim.append(total_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_cases_per_sim[39], label='Sim 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c5fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser-generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
